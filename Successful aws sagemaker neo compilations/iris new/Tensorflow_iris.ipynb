{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3, re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "\r\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1,4])\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    # Dense Layer\r\n",
      "\r\n",
      "    dense1 = tf.layers.dense(inputs=input_layer, units=10, activation=tf.nn.relu)\r\n",
      "    dense2 = tf.layers.dense(inputs=dense1, units=20, activation=tf.nn.relu)\r\n",
      "    dense3 = tf.layers.dense(inputs=dense2, units=10, activation=tf.nn.relu)\r\n",
      "    logits = tf.layers.dense(inputs=dense3, units=3, activation=None)\r\n",
      "    \r\n",
      "\r\n",
      "    # Define operations\r\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\r\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\r\n",
      "\r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.int32)\r\n",
      "        \r\n",
      "        loss = tf.losses.softmax_cross_entropy(\r\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=3), logits=logits)\r\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        predictions = {\r\n",
      "            'probabilities': probabilities\r\n",
      "        }\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        print(\"LABEL==>\")\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, tf.argmax(input=logits, axis=1))\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "def estimator_fn(run_config, params):\r\n",
      "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\r\n",
      "\r\n",
      "    return tf.estimator.DNNClassifier(feature_columns=feature_columns,\r\n",
      "                                      hidden_units=[10, 20, 10],\r\n",
      "                                      n_classes=3,\r\n",
      "                                      config=run_config)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_spec = tf.FixedLenFeature(dtype=tf.float32, shape=[4])\r\n",
      "\r\n",
      "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [1,4], name = 'data')}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "def parser(record):\r\n",
      "\r\n",
      "    features={\r\n",
      "    'feats': tf.FixedLenFeature([], tf.string),\r\n",
      "    'label': tf.FixedLenFeature([], tf.int64)\r\n",
      "     }\r\n",
      "   \r\n",
      "    \r\n",
      "    parsed = tf.parse_single_example(record, features)\r\n",
      "    #feats = tf.convert_to_tensor(parsed['feats'])\r\n",
      "    #feats = tf.decode_raw(parsed['feats'], tf.float32)\r\n",
      "    #feats.set_shape([4])\r\n",
      "    #image = tf.cast(feats, tf.float32)\r\n",
      "    feats = tf.convert_to_tensor(tf.decode_raw(parsed['feats'], tf.float64))\r\n",
      "    label = tf.cast(parsed['label'], tf.int32)\r\n",
      "\r\n",
      "    return {'feats': feats}, label\r\n",
      "\r\n",
      "\r\n",
      "'''\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    image = tf.decode_raw(features['image_raw'], tf.float64)\r\n",
      "    image.set_shape([4])\r\n",
      "    image = tf.cast(image, tf.float32)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "    #print(\"===>\", image.shape , label.shape, \"<===\")\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=1):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "    \r\n",
      "    image, label = read_and_decode(filename_queue)\r\n",
      "\r\n",
      "    images, labels = tf.train.batch(\r\n",
      "        [image, label], batch_size=batch_size,\r\n",
      "        capacity=10 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "def _input_fn(tfrecords_path , training_filename , batch_size=1):\r\n",
      "\r\n",
      "    dataset = (\r\n",
      "    tf.data.TFRecordDataset(tfrecords_path)\r\n",
      "    .map(parser)\r\n",
      "    .batch(1)\r\n",
      "    )\r\n",
      "  \r\n",
      "    iterator = dataset.make_one_shot_iterator()\r\n",
      "\r\n",
      "    batch_feats, batch_labels = iterator.get_next()\r\n",
      "\r\n",
      "    #return batch_feats, batch_labels\r\n",
      "    return {INPUT_TENSOR_NAME: batch_feats}, batch_labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def neo_preprocess(payload, content_type):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import io\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined pre-processing function')\r\n",
      "\r\n",
      "    if content_type != 'application/x-image' and content_type != 'application/vnd+python.numpy+binary':\r\n",
      "        raise RuntimeError('Content type must be application/x-image or application/vnd+python.numpy+binary')\r\n",
      "\r\n",
      "    f = io.BytesIO(payload)\r\n",
      "  \r\n",
      "    image = np.load(f)\r\n",
      "\r\n",
      "    return image\r\n",
      "\r\n",
      "### NOTE: this function cannot use MXNet\r\n",
      "def neo_postprocess(result):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import json\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined post-processing function')\r\n",
      "\r\n",
      "    # Softmax (assumes batch size 1)\r\n",
      "    result = np.squeeze(result)\r\n",
      "#     result_exp = np.exp(result - np.max(result))\r\n",
      "#     result = result_exp / np.sum(result_exp)\r\n",
      "\r\n",
      "    response_body = json.dumps(result.tolist())\r\n",
      "    content_type = 'application/json'\r\n",
      "\r\n",
      "    return response_body, content_type\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat iris_dnn_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     120    4  setosa  versicolor  virginica\n",
      "0    6.4  2.8     5.6         2.2          2\n",
      "1    5.0  2.3     3.3         1.0          1\n",
      "2    4.9  2.5     4.5         1.7          2\n",
      "3    4.9  3.1     1.5         0.1          0\n",
      "4    5.7  3.8     1.7         0.3          0\n",
      "..   ...  ...     ...         ...        ...\n",
      "115  5.5  2.6     4.4         1.2          1\n",
      "116  5.7  3.0     4.2         1.2          1\n",
      "117  4.4  2.9     1.4         0.2          0\n",
      "118  4.8  3.0     1.4         0.1          0\n",
      "119  5.5  2.4     3.7         1.0          1\n",
      "\n",
      "[120 rows x 5 columns]\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from six.moves.urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "\n",
    "    \n",
    "# Load datasets.\n",
    "train_set = pd.read_csv(IRIS_TRAINING)\n",
    "test_set =  pd.read_csv(IRIS_TEST)\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "data = asarray([[6.4,2.8,5.6,2.1]])\n",
    "save('data.npy', data)\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "#new_utils.convert_to_tfrecord(IRIS_TRAINING,IRIS_TEST)\n",
    "\n",
    "#dataset = utils.data_preprocess(train_set, test_set)\n",
    "\n",
    "\n",
    "\n",
    "!mkdir data\n",
    "\n",
    "'''\n",
    "train_dataset = utils.convert_to_new(dataset['train_dict']['features'], dataset['train_dict']['labels'], 'train', 'data')\n",
    "test_dataset = utils.convert_to_new(dataset['test_dict']['features'], dataset['test_dict']['labels'], 'test', 'data')\n",
    "#test_dataset = utils.convert_to_new(test_set, 'test', 'data')\n",
    "\n",
    "'''\n",
    "dataset = utils.data_preprocess(train_set, test_set)\n",
    "print(dataset['train_dict']['features'].shape)\n",
    "print(dataset['test_dict']['features'].shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "Writing data/train.tfrecords\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/Iris_New_Code/utils.py:73: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "Writing data/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import utils\n",
    "\n",
    "!mkdir data\n",
    "\n",
    "utils.convert_to(dataset[\"train_dict\"], 'train', 'data')\n",
    "\n",
    "utils.convert_to(dataset[\"test_dict\"], 'test', 'data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-southeast-1-018166606076\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/Iris_New_Data')\n",
    "# inputs = sagemaker_session.upload_data(path='dataset-tfrecord', key_prefix='data/Iris_New_Data')\n",
    "print(sagemaker_session.default_bucket())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "\r\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1,4])\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    # Dense Layer\r\n",
      "\r\n",
      "    dense1 = tf.layers.dense(inputs=input_layer, units=10, activation=tf.nn.relu)\r\n",
      "    dense2 = tf.layers.dense(inputs=dense1, units=20, activation=tf.nn.relu)\r\n",
      "    dense3 = tf.layers.dense(inputs=dense2, units=10, activation=tf.nn.relu)\r\n",
      "    logits = tf.layers.dense(inputs=dense3, units=3, activation=None)\r\n",
      "    \r\n",
      "\r\n",
      "    # Define operations\r\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\r\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\r\n",
      "\r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.int32)\r\n",
      "        \r\n",
      "        loss = tf.losses.softmax_cross_entropy(\r\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=3), logits=logits)\r\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        predictions = {\r\n",
      "            'probabilities': probabilities\r\n",
      "        }\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        print(\"LABEL==>\")\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, tf.argmax(input=logits, axis=1))\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "def estimator_fn(run_config, params):\r\n",
      "    feature_columns = [tf.feature_column.numeric_column(INPUT_TENSOR_NAME, shape=[4])]\r\n",
      "\r\n",
      "    return tf.estimator.DNNClassifier(feature_columns=feature_columns,\r\n",
      "                                      hidden_units=[10, 20, 10],\r\n",
      "                                      n_classes=3,\r\n",
      "                                      config=run_config)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_spec = tf.FixedLenFeature(dtype=tf.float32, shape=[4])\r\n",
      "\r\n",
      "    return tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)()\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [1,4], name = 'data')}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "def parser(record):\r\n",
      "\r\n",
      "    features={\r\n",
      "    'feats': tf.FixedLenFeature([], tf.string),\r\n",
      "    'label': tf.FixedLenFeature([], tf.int64)\r\n",
      "     }\r\n",
      "   \r\n",
      "    \r\n",
      "    parsed = tf.parse_single_example(record, features)\r\n",
      "    #feats = tf.convert_to_tensor(parsed['feats'])\r\n",
      "    #feats = tf.decode_raw(parsed['feats'], tf.float32)\r\n",
      "    #feats.set_shape([4])\r\n",
      "    #image = tf.cast(feats, tf.float32)\r\n",
      "    feats = tf.convert_to_tensor(tf.decode_raw(parsed['feats'], tf.float64))\r\n",
      "    label = tf.cast(parsed['label'], tf.int32)\r\n",
      "\r\n",
      "    return {'feats': feats}, label\r\n",
      "\r\n",
      "\r\n",
      "'''\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    image = tf.decode_raw(features['image_raw'], tf.float64)\r\n",
      "    image.set_shape([4])\r\n",
      "    image = tf.cast(image, tf.float32)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "    #print(\"===>\", image.shape , label.shape, \"<===\")\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=1):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "    \r\n",
      "    image, label = read_and_decode(filename_queue)\r\n",
      "\r\n",
      "    images, labels = tf.train.batch(\r\n",
      "        [image, label], batch_size=batch_size,\r\n",
      "        capacity=10 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "def _input_fn(tfrecords_path , training_filename , batch_size=1):\r\n",
      "\r\n",
      "    dataset = (\r\n",
      "    tf.data.TFRecordDataset(tfrecords_path)\r\n",
      "    .map(parser)\r\n",
      "    .batch(1)\r\n",
      "    )\r\n",
      "  \r\n",
      "    iterator = dataset.make_one_shot_iterator()\r\n",
      "\r\n",
      "    batch_feats, batch_labels = iterator.get_next()\r\n",
      "\r\n",
      "    #return batch_feats, batch_labels\r\n",
      "    return {INPUT_TENSOR_NAME: batch_feats}, batch_labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def neo_preprocess(payload, content_type):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import io\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined pre-processing function')\r\n",
      "\r\n",
      "    if content_type != 'application/x-image' and content_type != 'application/vnd+python.numpy+binary':\r\n",
      "        raise RuntimeError('Content type must be application/x-image or application/vnd+python.numpy+binary')\r\n",
      "\r\n",
      "    f = io.BytesIO(payload)\r\n",
      "  \r\n",
      "    image = np.load(f)\r\n",
      "\r\n",
      "    return image\r\n",
      "\r\n",
      "### NOTE: this function cannot use MXNet\r\n",
      "def neo_postprocess(result):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import json\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined post-processing function')\r\n",
      "\r\n",
      "    # Softmax (assumes batch size 1)\r\n",
      "    result = np.squeeze(result)\r\n",
      "#     result_exp = np.exp(result - np.max(result))\r\n",
      "#     result = result_exp / np.sum(result_exp)\r\n",
      "\r\n",
      "    response_body = json.dumps(result.tolist())\r\n",
      "    content_type = 'application/json'\r\n",
      "\r\n",
      "    return response_body, content_type\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'iris_dnn_classifier.py'\n",
    "# !cat 'tf_Script.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-08 13:46:32 Starting - Starting the training job...\n",
      "2020-10-08 13:46:34 Starting - Launching requested ML instances......\n",
      "2020-10-08 13:47:53 Starting - Preparing the instances for training......\n",
      "2020-10-08 13:49:03 Downloading - Downloading input data\n",
      "2020-10-08 13:49:03 Training - Downloading the training image...\n",
      "2020-10-08 13:49:22 Training - Training image download completed. Training in progress.\u001b[34m2020-10-08 13:49:22,127 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:22,127 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:22,141 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-ap-southeast-1-018166606076/sagemaker-tensorflow-2020-10-08-13-46-32-082/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,727 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,728 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,728 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f365cf37610>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,729 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24.790927: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24.791649: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,928 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,930 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:24,954 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34mLABEL==>\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25,203 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25,204 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.218066: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.218097: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.242782: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.242816: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.271726: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.271756: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.295062: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:25.295128: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26,100 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26.108589: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26.108658: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26,240 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26,244 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26,267 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26.324644: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26.324687: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:26,720 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:27.430640: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:27.430684: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:27,765 INFO - tensorflow - loss = 1.639272, step = 1\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,058 INFO - tensorflow - global_step/sec: 341.719\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,059 INFO - tensorflow - loss = 0.6853829, step = 101 (0.293 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,229 INFO - tensorflow - global_step/sec: 582.741\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,230 INFO - tensorflow - loss = 0.14684518, step = 201 (0.171 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,399 INFO - tensorflow - global_step/sec: 588.546\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,400 INFO - tensorflow - loss = 0.97621125, step = 301 (0.170 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,575 INFO - tensorflow - global_step/sec: 569.337\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,576 INFO - tensorflow - loss = 0.33634576, step = 401 (0.176 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,741 INFO - tensorflow - global_step/sec: 602.465\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,741 INFO - tensorflow - loss = 0.24901152, step = 501 (0.166 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,907 INFO - tensorflow - global_step/sec: 603.078\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:28,907 INFO - tensorflow - loss = 0.14902735, step = 601 (0.166 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,071 INFO - tensorflow - global_step/sec: 607.194\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,072 INFO - tensorflow - loss = 0.012465893, step = 701 (0.165 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,238 INFO - tensorflow - global_step/sec: 600.373\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,239 INFO - tensorflow - loss = 0.005564438, step = 801 (0.167 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,404 INFO - tensorflow - global_step/sec: 602.613\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,405 INFO - tensorflow - loss = 0.21626791, step = 901 (0.166 sec)\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:29,583 INFO - tensorflow - Saving checkpoints for 1000 into s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/model.ckpt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-10-08 13:49:30.319193: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:30.319237: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:30,696 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:30,802 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:30,820 INFO - tensorflow - Starting evaluation at 2020-10-08-13:49:30\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:30,953 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,261 INFO - tensorflow - Restoring parameters from s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,403 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,412 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,502 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,515 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,528 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,541 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,555 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,568 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,582 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,595 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,611 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,625 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,651 INFO - tensorflow - Finished evaluation at 2020-10-08-13:49:31\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,651 INFO - tensorflow - Saving dict for global step 1000: accuracy = 0.97, global_step = 1000, loss = 0.12723938\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.661806: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.661838: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.682247: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.682338: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.703775: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31.703811: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:31,967 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1000: s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.032340: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.032376: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.056450: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.056486: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.072947: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.072977: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.094582: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.094611: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.125390: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.125433: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.145291: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.145362: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,230 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,285 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,286 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,286 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,286 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,286 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,286 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,366 INFO - tensorflow - Restoring parameters from s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/model.ckpt-1000\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,496 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,497 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32,497 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.508153: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.508184: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.526878: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.526908: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.545566: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:32.545595: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.159052: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.159099: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33,243 INFO - tensorflow - SavedModel written to: s3://sagemaker-ap-southeast-1-018166606076/IrisModel/sagemaker-tensorflow-2020-10-08-13-46-32-082/checkpoints/export/Servo/temp-1602164972/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.250197: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.250234: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.903189: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.903229: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.928389: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:33.928419: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:34,036 INFO - tensorflow - Loss for final step: 0.009448454.\u001b[0m\n",
      "\u001b[34m2020-10-08 13:49:34,185 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1602164972\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-10-08 13:49:44 Uploading - Uploading generated training model\n",
      "2020-10-08 13:49:44 Completed - Training job completed\n",
      "Training seconds: 56\n",
      "Billable seconds: 56\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "output_path = \"s3://sagemaker-ap-southeast-1-018166606076/IrisModel\"\n",
    "\n",
    "iris_estimator = TensorFlow(entry_point='iris_dnn_classifier.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.11.0',\n",
    "                             output_path = output_path,\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=1,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "iris_estimator.fit(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-018166606076\n",
      "?.....!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The instance type rasp3b is not supported for deployment via SageMaker.Please deploy the model manually.\n"
     ]
    }
   ],
   "source": [
    "# output_path = '/'.join(iris_estimator.output_path.split('/')[:-1])\n",
    "\n",
    "# print(output_path)\n",
    "\n",
    "\n",
    "# optimized_estimator = iris_estimator.compile_model(target_instance_family='rasp3b',\n",
    "#                               output_path=output_path,\n",
    "#                               input_shape= {'data':[1,4]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "#                               framework='tensorflow', framework_version='1.11.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "#iris_predictor = iris_estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'probabilities': {'dtype': 1, 'tensor_shape': {'dim': [{'size': 1}, {'size': 3}]}, 'float_val': [3.410078352317214e-05, 0.021960366517305374, 0.978005588054657]}}, 'model_spec': {'name': 'generic_model', 'version': {'value': 1602164972}, 'signature_name': 'serving_default'}}\n"
     ]
    }
   ],
   "source": [
    "#res = iris_predictor.predict([6.4,2.8,5.6,2.1]) \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker.Session().delete_endpoint(iris_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
