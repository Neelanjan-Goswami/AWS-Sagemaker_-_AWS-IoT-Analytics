{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3, re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = 'sagemaker-iris-classification'\n",
    "prefix = 'iris-tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat iris_dnn_classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/Aneeq/IRIS_Classification/new_utils.py:32: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_dataset = utils.convert_to_new(dataset['train_dict']['features'], dataset['train_dict']['labels'], 'train', 'data')\\ntest_dataset = utils.convert_to_new(dataset['test_dict']['features'], dataset['test_dict']['labels'], 'test', 'data')\\n#test_dataset = utils.convert_to_new(test_set, 'test', 'data')\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from six.moves.urllib.request import urlopen\n",
    "import pandas as pd\n",
    "#import utilsCopy1\n",
    "import new_utils\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "\n",
    "    \n",
    "# Load datasets.\n",
    "train_set = pd.read_csv(IRIS_TRAINING)\n",
    "test_set =  pd.read_csv(IRIS_TEST)\n",
    "\n",
    "\n",
    "new_utils.convert_to_tfrecord(IRIS_TRAINING,IRIS_TEST)\n",
    "\n",
    "#dataset = utilsCopy1.data_preprocess(train_set, test_set)\n",
    "\n",
    "\n",
    "\n",
    "#!mkdir data\n",
    "\n",
    "'''\n",
    "train_dataset = utils.convert_to_new(dataset['train_dict']['features'], dataset['train_dict']['labels'], 'train', 'data')\n",
    "test_dataset = utils.convert_to_new(dataset['test_dict']['features'], dataset['test_dict']['labels'], 'test', 'data')\n",
    "#test_dataset = utils.convert_to_new(test_set, 'test', 'data')\n",
    "\n",
    "'''\n",
    "# dataset = utils.data_preprocess(train_set, test_set)\n",
    "# print(dataset['train_dict']['features'].shape)\n",
    "# print(dataset['test_dict']['features'].shape)\n",
    "# print(dataset['valid_dict']['features'].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import utilsCopy1\n",
    "\n",
    "# !mkdir data\n",
    "\n",
    "# utilsCopy1.convert_to(dataset[\"train_dict\"], 'train', 'data')\n",
    "# #utils.convert_to(dataset[\"valid_dict\"], 'validation', 'data')\n",
    "# utilsCopy1.convert_to(dataset[\"test_dict\"], 'test', 'data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data',bucket=bucket, key_prefix='data/Iris_New_Data')\n",
    "#boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'datatrain/train.tfrecords')).upload_file('dataset-tfrecord/train.tfrecords')\n",
    "#boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'datatest/test.tfrecords')).upload_file('dataset-tfrecord/test.tfrecords')\n",
    "#inputs = sagemaker_session.upload_data(path='dataset-tfrecord', key_prefix='data/Iris_New_Data')\n",
    "#print(sagemaker_session.default_bucket())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/datatrain'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat 'iris_dnn_classifier.py'\n",
    "# !cat 'tf_Script.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-08 10:32:02 Starting - Starting the training job...\n",
      "2020-10-08 10:32:03 Starting - Launching requested ML instances......\n",
      "2020-10-08 10:33:04 Starting - Preparing the instances for training...\n",
      "2020-10-08 10:33:54 Downloading - Downloading input data...\n",
      "2020-10-08 10:34:27 Training - Training image download completed. Training in progress.\n",
      "2020-10-08 10:34:27 Uploading - Uploading generated training model\u001b[34m2020-10-08 10:34:22,529 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:22,530 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:22,543 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-iris-classification/sagemaker-tensorflow-2020-10-08-10-32-01-729/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,430 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,430 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,430 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,430 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,430 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,431 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,431 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,431 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f14398b71d0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-iris-classification/iris-tfrecord/model/sagemaker-tensorflow-2020-10-08-10-32-01-729/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,432 WARNING - tf_container - serving_input_fn not specified, model NOT saved, use checkpoints to reconstruct\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,432 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25.498285: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25.499097: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m('training_dir', u'/opt/ml/input/data/training')\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,587 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-08 10:34:25,594 ERROR - container_support.training - uncaught exception during training: Failed to convert object of type <type 'dict'> to Tensor. Contents: {'sepal_width': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float32>, 'petal_length': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float32>, 'sepal_length': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float32>, 'label': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int64>}. Consider casting elements to a supported type.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n",
      "    fw.train()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 173, in train\n",
      "    train_wrapper.train()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n",
      "    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 637, in run\n",
      "    getattr(self, task_to_run)()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 674, in run_master\n",
      "    self._start_distributed_training(saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 788, in _start_distributed_training\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1181, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1211, in _train_model_default\n",
      "    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1169, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 108, in _model_fn\n",
      "    return self.customer_script.model_fn(features, labels, mode, params)\n",
      "  File \"/opt/ml/code/tf_Script.py\", line 70, in model_fn\n",
      "    net = tf.reshape(features, [-1,4])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6296, in reshape\n",
      "    \"Reshape\", tensor=tensor, shape=shape, name=name)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 513, in _apply_op_helper\n",
      "    raise err\u001b[0m\n",
      "\u001b[34mTypeError: Failed to convert object of type <type 'dict'> to Tensor. Contents: {'sepal_width': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float32>, 'petal_length': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float32>, 'sepal_length': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float32>, 'label': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int64>}. Consider casting elements to a supported type.\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-08 10:35:14 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-tensorflow-2020-10-08-10-32-01-729: Failed. Reason: AlgorithmError: uncaught exception during training: Failed to convert object of type <type 'dict'> to Tensor. Contents: {'sepal_width': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float32>, 'petal_length': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float32>, 'sepal_length': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float32>, 'label': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int64>}. Consider casting elements to a supported type.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n    fw.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 173, in train\n    train_wrapper.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cd8eb27d7b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                              train_instance_type='ml.c4.xlarge')\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0miris_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/estimator.py\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                 ),\n\u001b[1;32m   2670\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m             )\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-tensorflow-2020-10-08-10-32-01-729: Failed. Reason: AlgorithmError: uncaught exception during training: Failed to convert object of type <type 'dict'> to Tensor. Contents: {'sepal_width': <tf.Tensor 'IteratorGetNext:3' shape=(?,) dtype=float32>, 'petal_length': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=float32>, 'sepal_length': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float32>, 'label': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int64>}. Consider casting elements to a supported type.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n    fw.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 173, in train\n    train_wrapper.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in "
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "output_path = \"s3://sagemaker-iris-classification/iris-tfrecord/model\"\n",
    "\n",
    "iris_estimator = TensorFlow(entry_point='tf_Script.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.11.0',\n",
    "                             output_path = output_path,\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=1,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "iris_estimator.fit(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = '/'.join(iris_estimator.output_path.split('/')[:-1])\n",
    "\n",
    "# print(output_path)\n",
    "\n",
    "\n",
    "# optimized_estimator = iris_estimator.compile_model(target_instance_family='rasp3b',\n",
    "#                               output_path=output_path,\n",
    "#                               input_shape= {'inputs':[1,4]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "#                               framework='tensorflow', framework_version='1.11.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_predictor = iris_estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris_predictor.predict([4.6,3.6,1.0,0.2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
