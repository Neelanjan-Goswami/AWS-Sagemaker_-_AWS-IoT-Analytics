{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HPIKysQO1f-B",
    "outputId": "c058322a-9f3e-413a-92ee-580b8396ebaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3, re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import datetime\n",
    "import time\n",
    "import tfrecord_conversion\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer,RealTimePredictor\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket='tensorflow-rul'\n",
    "prefix='RUL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GbM4wNuR1f-K"
   },
   "outputs": [],
   "source": [
    "# source_data_location = 's3://sagemaker-solutions-us-west-2/Predictive-maintenance-using-machine-learning/data'\n",
    "\n",
    "# #local data folder\n",
    "# data_folder = 'data'\n",
    "\n",
    "# !aws s3 cp --recursive $source_data_location $data_folder\n",
    "\n",
    "\n",
    "# with zipfile.ZipFile(os.path.join(data_folder, 'CMAPSSData.zip'), \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r7FcblQz1f-P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20626, 5, 24)\n",
      "(20626,)\n",
      "(13091, 5, 24)\n",
      "(13091,)\n"
     ]
    }
   ],
   "source": [
    "# train_df, test_df, columns = utils.preprocess_data(data_folder)\n",
    "# test_set = pd.DataFrame()\n",
    "# for i in train_df:\n",
    "#     train_set=pd.DataFrame(i)\n",
    "\n",
    "# for i in test_df:\n",
    "#     test_set=pd.DataFrame(i)\n",
    "# test_set.to_csv('test_set.csv')\n",
    "# print(test_set.shape[1])\n",
    "\n",
    "\n",
    "train_set = pd.read_csv('newtrain.csv', index_col = 0)\n",
    "\n",
    "test_set = pd.read_csv('newtest.csv', index_col = 0)\n",
    "\n",
    "dataset = tfrecord_conversion.data_preprocess(train_set, test_set)\n",
    "print(dataset[\"train_dict\"][\"features\"].shape)\n",
    "print(dataset[\"train_dict\"][\"labels\"].shape)\n",
    "print(dataset[\"test_dict\"][\"features\"].shape)\n",
    "print(dataset[\"test_dict\"][\"labels\"].shape)\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "# define data\n",
    "\n",
    "# save to npy file\n",
    "\n",
    "save('train_feat.npy',dataset[\"train_dict\"][\"features\"])\n",
    "save('train_label.npy',dataset[\"train_dict\"][\"labels\"])\n",
    "save('test_feat.npy',dataset[\"test_dict\"][\"features\"])\n",
    "save('test_label.npy',dataset[\"test_dict\"][\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bc76M8FA1f-U",
    "outputId": "11b0cb5c-fe12-41b6-bdc6-713400f2670a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘tfrecord_data’: File exists\n",
      "Writing tfrecord_data/train.tfrecords\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/Predictive_Maintenance/RUL_Prediction_Tensorflow/tfrecord_conversion.py:91: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "Writing tfrecord_data/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "!mkdir 'tfrecord_data'\n",
    "\n",
    "\n",
    "\n",
    "tfrecord_conversion.convert_to(dataset[\"train_dict\"], 'train', 'tfrecord_data')\n",
    "tfrecord_conversion.convert_to(dataset[\"test_dict\"], 'test', 'tfrecord_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m4c6DXA31f-e"
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='tfrecord_data',bucket=bucket, key_prefix='data/RUL_Tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G-GBZbAw1f-l",
    "outputId": "9267045a-13cc-43ab-87da-7e164ac92bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import numpy as np\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "\r\n",
      "\r\n",
      "#     input_layer = tf.reshape(features[INPUT_TENSOR_NAME],[-1,26])\r\n",
      "\r\n",
      "#     dense1 = tf.layers.dense(inputs=input_layer, units=128, activation=tf.nn.relu)\r\n",
      "# #    drop1 = tf.layers.dropout(dense1, rate=0.5)\r\n",
      "#     dense2 = tf.layers.dense(inputs=dense1, units=64, activation=tf.nn.relu)\r\n",
      "# #    drop2 = tf.layers.dropout(dense2, rate=0.5)\r\n",
      "#     dense3 = tf.layers.dense(inputs=dense2, units=32, activation=tf.nn.relu)\r\n",
      "# #     drop3 = tf.layers.dropout(dense3, rate=0.5)\r\n",
      "#     dense4 = tf.layers.dense(inputs=dense3, units=16, activation=tf.nn.relu)\r\n",
      "# #     drop4 = tf.layers.dropout(dense3, rate=0.5)\r\n",
      "#     logits = tf.layers.dense(inputs=dense4, units=1, activation=tf.nn.relu)\r\n",
      "    batch_size = 1\r\n",
      "#     num_iterations = 1000\r\n",
      "    timesteps = 5\r\n",
      "    element_size = 24\r\n",
      "    num_classes = 1\r\n",
      "    hidden_layer_size = 128\r\n",
      "    _inputs = tf.reshape(features[INPUT_TENSOR_NAME], [-1,timesteps,element_size])\r\n",
      "#     y = tf.placeholder(tf.float32, shape=[num_classes],name='inputs')\r\n",
      "#     _inputs = tf.placeholder(tf.float32,shape=[1, timesteps,element_size],name='inputs')\r\n",
      "#     y = tf.placeholder(tf.float32, shape=[1, num_classes],name='inputs')\r\n",
      "    \r\n",
      "\r\n",
      "    # TensorFlow built-in functions\r\n",
      "    rnn_cell = tf.contrib.rnn.BasicRNNCell(hidden_layer_size)\r\n",
      "    outputs, _ = tf.nn.dynamic_rnn(rnn_cell, _inputs, dtype=tf.float32)\r\n",
      "    Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes],mean=0,stddev=.01))\r\n",
      "    bl = tf.Variable(tf.truncated_normal([num_classes],mean=0,stddev=.01))\r\n",
      "    last_rnn_output = outputs[:,-1,:]\r\n",
      "    final_output = tf.matmul(last_rnn_output, Wl) + bl\r\n",
      "#     softmax = tf.nn.softmax_cross_entropy_with_logits(logits=final_output,labels=y)\r\n",
      "\r\n",
      "    \r\n",
      "    \r\n",
      "\r\n",
      "    # Define operations\r\n",
      "#     predictions = last_rnn_output\r\n",
      "    \r\n",
      "    predictions = tf.squeeze(final_output,1) \r\n",
      "#     predictions = tf.nn.softmax(final_output, name='softmax_tensor')\r\n",
      "#     predictions_final = tf.split(final_output,5,axis=0)\r\n",
      "    \r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        prediction = {'Pred_RUL':final_output}\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(prediction)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=prediction, export_outputs=export_outputs)\r\n",
      "    \r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.float32)\r\n",
      "        loss = tf.losses.mean_squared_error(label_indices, predictions)\r\n",
      "        batch_size = tf.shape(labels)[0]\r\n",
      "        total_loss = tf.to_float(batch_size) * loss\r\n",
      "#         loss = tf.losses.softmax_cross_entropy(\r\n",
      "#             onehot_labels=tf.one_hot(label_indices, depth=1), logits=logits)\r\n",
      "#         tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        print(\"LABEL==>\")\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'rmse': tf.metrics.root_mean_squared_error(label_indices, predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [1,5,24], name = 'data')}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'feature_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    feature = tf.decode_raw(features['feature_raw'], tf.float64)\r\n",
      "    feature.set_shape([120])\r\n",
      "    feature = tf.cast(feature, tf.float32)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "    #print(\"===>\", image.shape , label.shape, \"<===\")\r\n",
      "    return feature, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=1)\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=1):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "    \r\n",
      "    feature, labels = read_and_decode(filename_queue)\r\n",
      "\r\n",
      "    feature, labels = tf.train.batch(\r\n",
      "        [feature, labels], batch_size=batch_size,\r\n",
      "        capacity=10 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: feature}, labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "def _input_fn(tfrecords_path , training_filename , batch_size=1):\r\n",
      "\r\n",
      "    dataset = (\r\n",
      "    tf.data.TFRecordDataset(tfrecords_path)\r\n",
      "    .map(parser)\r\n",
      "    .batch(1)\r\n",
      "    )\r\n",
      "  \r\n",
      "    iterator = dataset.make_one_shot_iterator()\r\n",
      "\r\n",
      "    batch_feats, batch_labels = iterator.get_next()\r\n",
      "\r\n",
      "    #return batch_feats, batch_labels\r\n",
      "    return {INPUT_TENSOR_NAME: batch_feats}, batch_labels\r\n",
      "\r\n",
      "'''\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def neo_preprocess(payload, content_type):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import io\r\n",
      "    logging.info('Invoking user-defined pre-processing function')\r\n",
      "\r\n",
      "#     if content_type != 'text/csv' or content_type != 'application/vnd+python.numpy+binary':\r\n",
      "#         raise RuntimeError('Content type must be application/x-image or application/vnd+python.numpy+binary')\r\n",
      "\r\n",
      "#     f = payload\r\n",
      "  \r\n",
      "#     image = np.load(f)\r\n",
      "    image={'data':payload}\r\n",
      "\r\n",
      "    return image\r\n",
      "\r\n",
      "### NOTE: this function cannot use MXNet\r\n",
      "def neo_postprocess(result):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import json\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined post-processing function')\r\n",
      "\r\n",
      "    # Softmax (assumes batch size 1)\r\n",
      "    result = np.squeeze(result)\r\n",
      "#     result_exp = np.exp(result - np.max(result))\r\n",
      "#     result = result_exp / np.sum(result_exp)\r\n",
      "\r\n",
      "    response_body = json.dumps(result.tolist())\r\n",
      "    content_type = 'application/json'\r\n",
      "\r\n",
      "    return response_body, content_type\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat dnn_regressor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tZfjTv0b1f-q",
    "outputId": "c07c860c-b8b4-4294-8e28-2f7afefbe1e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-20 11:10:28 Starting - Starting the training job...\n",
      "2020-10-20 11:10:30 Starting - Launching requested ML instances......\n",
      "2020-10-20 11:11:32 Starting - Preparing the instances for training...\n",
      "2020-10-20 11:12:28 Downloading - Downloading input data\n",
      "2020-10-20 11:12:28 Training - Downloading the training image...\n",
      "2020-10-20 11:12:47 Training - Training image download completed. Training in progress.\u001b[34m2020-10-20 11:12:47,457 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:47,458 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:47,471 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://tensorflow-rul/sagemaker-tensorflow-2020-10-20-11-10-27-840/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,059 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,060 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,060 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f74e56b8610>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,061 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50.108772: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50.109490: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,276 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,278 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:50,299 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34mLABEL==>\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:51,958 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:51,960 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:51.976533: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:51.976578: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.013867: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.013951: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.060936: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.061019: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.094304: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.094352: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52,937 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.949971: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:52.950003: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53,082 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53,086 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53,104 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53.178527: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53.178572: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:53,906 INFO - tensorflow - Saving checkpoints for 0 into s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:54.734499: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:54.734549: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:55,423 INFO - tensorflow - loss = 36500.605, step = 1\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:55,848 INFO - tensorflow - global_step/sec: 235.334\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:55,848 INFO - tensorflow - loss = 6135.374, step = 101 (0.425 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,108 INFO - tensorflow - global_step/sec: 384.354\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,109 INFO - tensorflow - loss = 67710.27, step = 201 (0.260 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,356 INFO - tensorflow - global_step/sec: 402.463\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,357 INFO - tensorflow - loss = 19958.598, step = 301 (0.249 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,591 INFO - tensorflow - global_step/sec: 425.84\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,592 INFO - tensorflow - loss = 1064.0806, step = 401 (0.235 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,842 INFO - tensorflow - global_step/sec: 397.977\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:56,843 INFO - tensorflow - loss = 12121.585, step = 501 (0.251 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,107 INFO - tensorflow - global_step/sec: 378.299\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,108 INFO - tensorflow - loss = 9.522964, step = 601 (0.265 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,367 INFO - tensorflow - global_step/sec: 384.704\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,367 INFO - tensorflow - loss = 7922.13, step = 701 (0.260 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,613 INFO - tensorflow - global_step/sec: 406.177\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,614 INFO - tensorflow - loss = 275.16193, step = 801 (0.246 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,859 INFO - tensorflow - global_step/sec: 406.006\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:57,860 INFO - tensorflow - loss = 20957.922, step = 901 (0.246 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,133 INFO - tensorflow - global_step/sec: 365.715\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,134 INFO - tensorflow - loss = 1071.1757, step = 1001 (0.273 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,486 INFO - tensorflow - global_step/sec: 282.679\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,487 INFO - tensorflow - loss = 4371.757, step = 1101 (0.354 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,734 INFO - tensorflow - global_step/sec: 403.685\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:58,735 INFO - tensorflow - loss = 299.8225, step = 1201 (0.248 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,007 INFO - tensorflow - global_step/sec: 366.362\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,008 INFO - tensorflow - loss = 6294.4077, step = 1301 (0.273 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,282 INFO - tensorflow - global_step/sec: 364.058\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,283 INFO - tensorflow - loss = 4319.636, step = 1401 (0.275 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,515 INFO - tensorflow - global_step/sec: 428.691\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,516 INFO - tensorflow - loss = 1402.5023, step = 1501 (0.233 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,768 INFO - tensorflow - global_step/sec: 395.413\u001b[0m\n",
      "\u001b[34m2020-10-20 11:12:59,769 INFO - tensorflow - loss = 302.5599, step = 1601 (0.253 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,029 INFO - tensorflow - global_step/sec: 383.157\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,030 INFO - tensorflow - loss = 6233.874, step = 1701 (0.261 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,264 INFO - tensorflow - global_step/sec: 425.349\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,265 INFO - tensorflow - loss = 267.20596, step = 1801 (0.235 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,493 INFO - tensorflow - global_step/sec: 436.188\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,494 INFO - tensorflow - loss = 6348.2056, step = 1901 (0.229 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,733 INFO - tensorflow - global_step/sec: 416.732\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,734 INFO - tensorflow - loss = 1178.975, step = 2001 (0.240 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,976 INFO - tensorflow - global_step/sec: 411.364\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:00,977 INFO - tensorflow - loss = 4149.7915, step = 2101 (0.243 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,225 INFO - tensorflow - global_step/sec: 401.639\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,226 INFO - tensorflow - loss = 5039.998, step = 2201 (0.249 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,467 INFO - tensorflow - global_step/sec: 414.497\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,467 INFO - tensorflow - loss = 1125.6836, step = 2301 (0.241 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,698 INFO - tensorflow - global_step/sec: 432.811\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,699 INFO - tensorflow - loss = 1943.3661, step = 2401 (0.231 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,931 INFO - tensorflow - global_step/sec: 428.69\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:01,932 INFO - tensorflow - loss = 3138.5896, step = 2501 (0.233 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,307 INFO - tensorflow - global_step/sec: 265.583\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,308 INFO - tensorflow - loss = 111.46747, step = 2601 (0.376 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,547 INFO - tensorflow - global_step/sec: 417.094\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,548 INFO - tensorflow - loss = 7036.1895, step = 2701 (0.240 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,788 INFO - tensorflow - global_step/sec: 414.558\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:02,789 INFO - tensorflow - loss = 65.42965, step = 2801 (0.241 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:03,043 INFO - tensorflow - global_step/sec: 392.372\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:03,044 INFO - tensorflow - loss = 11255.753, step = 2901 (0.255 sec)\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:03,408 INFO - tensorflow - Saving checkpoints for 3000 into s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:04.530476: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:04.530522: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,112 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,318 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,336 INFO - tensorflow - Starting evaluation at 2020-10-20-11:13:05\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,399 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,462 INFO - tensorflow - Restoring parameters from s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/model.ckpt-3000\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,620 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,629 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,740 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,749 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,757 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,764 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,774 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,783 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,793 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,803 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-10-20 11:13:05,812 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,821 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,849 INFO - tensorflow - Finished evaluation at 2020-10-20-11:13:05\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05,849 INFO - tensorflow - Saving dict for global step 3000: global_step = 3000, loss = 2066.2896, rmse = 45.45646\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.861791: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.861829: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.916036: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.916087: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.952008: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:05.952060: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06,531 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 3000: s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/model.ckpt-3000\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.647180: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.647230: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.701518: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.701552: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.736722: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.736755: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.785697: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.785750: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.836738: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.836777: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.874828: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:06.874861: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,226 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,311 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,311 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,311 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,311 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,312 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,312 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,388 INFO - tensorflow - Restoring parameters from s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/model.ckpt-3000\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,531 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,531 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07,531 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.546387: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.546419: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.595839: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.595880: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.647053: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:07.647087: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:08.507714: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:08.507804: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:08,842 INFO - tensorflow - SavedModel written to: s3://tensorflow-rul/RUL/sagemaker-tensorflow-2020-10-20-11-10-27-840/checkpoints/export/Servo/temp-1603192386/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:08.852744: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:08.852783: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09.278034: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09.278090: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09.315170: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09.315228: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09,508 INFO - tensorflow - Loss for final step: 11.294783.\u001b[0m\n",
      "\u001b[34m2020-10-20 11:13:09,834 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1603192386\u001b[0m\n",
      "\n",
      "2020-10-20 11:13:20 Uploading - Uploading generated training model\n",
      "2020-10-20 11:13:20 Completed - Training job completed\n",
      "Training seconds: 59\n",
      "Billable seconds: 59\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "output_path = \"s3://tensorflow-rul/RUL\"\n",
    "\n",
    "RUL_estimator = TensorFlow(entry_point='dnn_regressor.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.11.0',\n",
    "                             output_path = output_path,\n",
    "                             training_steps=3000, \n",
    "                             evaluation_steps=100,\n",
    "                             #early_stopping=\"true\",\n",
    "                             #patience=\"5\",\n",
    "                             train_instance_count=1,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "RUL_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-Hp6Myq1f-v"
   },
   "outputs": [],
   "source": [
    "# output_path = '/'.join(RUL_estimator.output_path.split('/')[:-1])\n",
    "\n",
    "# print(output_path)\n",
    "# # \n",
    "\n",
    "# optimized_estimator = RUL_estimator.compile_model(target_instance_family='rasp3b',\n",
    "#                               output_path=output_path,\n",
    "#                               input_shape= {'data':[1,5,24]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "#                               framework='tensorflow', framework_version='1.11.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hLWvovEY1f-z",
    "outputId": "cd803250-4baa-4932-e1a9-48dc3be192d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "RUL_predictor = RUL_estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hxCL2zRK1f-2"
   },
   "outputs": [],
   "source": [
    "RUL_predictor.content_type = 'text/csv'\n",
    "RUL_predictor.serializer = csv_serializer\n",
    "RUL_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KDqNXffJ1f-7"
   },
   "outputs": [],
   "source": [
    "test=test_set\n",
    "test = test.drop(columns='RUL')\n",
    "test.to_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "34dwJIQ41f-_",
    "outputId": "83413331-9908-49b0-f1ec-1130cf7f1ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13096, 26)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RD2Wpfl_1f_C"
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"trial.csv\", index_col= 0)\n",
    "\n",
    "test_feature_dataset = test_dataset[['id', 'cycle','setting1', 'setting2', 'setting3', 's1', 's2', 's3','s4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14','s15', 's16', 's17', 's18', 's19', 's20', 's21'\n",
    "]]\n",
    "#print(test_feature_dataset)\n",
    "test_features = np.array(test_feature_dataset.values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tf in test_features:\n",
    "#     prediction=RUL_predictor.predict(tf)\n",
    "#     print(prediction['outputs']['Pred_RUL']['floatVal'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# x = []\n",
    "# y1 = []\n",
    "# # y2 = [] \n",
    "# id_data = []\n",
    "# id_data = np.array(test_set[test['id']==1]['RUL'])\n",
    "# print(id_data.shape)\n",
    "# for i in range(len(id_data)):x.append(i)\n",
    "# print(x)\n",
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# for tf in x:\n",
    "    \n",
    "# #     print(test_features[tf])\n",
    "# #     print(tf)\n",
    "#     prediction = RUL_predictor.predict(tfrecord_conversion.lstm_preprocess(test_set,5))\n",
    "# #     x.append(tf)\n",
    "#     y1.append(prediction['outputs']['Pred_RUL']['floatVal'][0])\n",
    "# #     y2.append(test_set['RUL'].loc[tf])\n",
    "# #print(test_set[test['id']==2])\n",
    "# #     print(id_data[tf],prediction['outputs']['Pred_RUL']['floatVal'][0]  )\n",
    "\n",
    "# print(len(y1))\n",
    "# plt.plot(x, y1, color='k', label='Predicted RUL')\n",
    "# plt.plot(x, id_data, color='b', label='Actual RUL')\n",
    "\n",
    "# plt.xlabel('Cycles')\n",
    "# plt.ylabel('RUL')\n",
    "\n",
    "# print(\"RUL\", id_data[0], max(y1))\n",
    "\n",
    "# # plt.legend()\n",
    "# # plt.savefig('testplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1yD6YvjM1f_G",
    "outputId": "4f026dd6-ddb6-4a9b-e3e6-8d43bf1d9a9f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# x = []\n",
    "# y1 = []\n",
    "# y2 = [] \n",
    "# id_no = 1\n",
    "# id_data = []\n",
    "# id_data = np.array(test_set[test_set['id']==id_no]['RUL'])\n",
    "# print(id_data)\n",
    "# for i in range(len(id_data)):x.append(i)\n",
    "# print(x)\n",
    "# test_features = np.array(test[test['id']==id_no])\n",
    "# for tf in x:\n",
    "#     prediction = RUL_predictor.predict(test_features[tf])\n",
    "#     y1.append(prediction['outputs']['Pred_RUL']['floatVal'][0])\n",
    "\n",
    "# print(y1)\n",
    "\n",
    "# plt.plot(x, y1, color='k', label='Predicted RUL')\n",
    "# plt.plot(x, id_data, color='b', label='Actual RUL')\n",
    "\n",
    "# plt.xlabel('Cycles')\n",
    "# plt.ylabel('RUL')\n",
    "# plt.legend()\n",
    "# plt.savefig('testplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BteQGmGq1gBF"
   },
   "outputs": [],
   "source": [
    "# optimized_predictor = optimized_estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = 'insert name of your endpoint here'\n",
    "# payload = test_dataset\n",
    "# predictor = RealTimePredictor(endpoint=endpoint, content_type='text/csv')\n",
    "# inference_response = predictor.predict(data=payload)\n",
    "# print (inference_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized_predictor.content_type = 'text/csv'\n",
    "# optimized_predictor.serializer = csv_serializer\n",
    "# optimized_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputs': {'Pred_RUL': {'dtype': 'DT_FLOAT', 'floatVal': [99.37246704101562], 'tensorShape': {'dim': [{'size': '1'}, {'size': '1'}]}}}, 'modelSpec': {'version': '1603192386', 'name': 'generic_model', 'signatureName': 'serving_default'}}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "x = []\n",
    "y1 = []\n",
    "y2 = [] \n",
    "\n",
    "testdata = tfrecord_conversion.lstm_preprocess(test_set,5)\n",
    "# print(testdata.shape)\n",
    "pred = RUL_predictor.predict(testdata)\n",
    "print(pred)\n",
    "# for tf in range(10):\n",
    "#     print(tf, testdata[tf])\n",
    "# #     prediction = RUL_predictor.predict(testdata[tf])\n",
    "# #     x.append(tf)\n",
    "# #     y1.append(prediction['outputs']['Pred_RUL']['floatVal'][0])\n",
    "# #     y2.append(test_set['RUL'].loc[tf])\n",
    "# plt.plot(x, y1, color='k', label='Predicted RUL')\n",
    "# plt.plot(x, y2, color='b', label='Actual RUL')\n",
    "\n",
    "# plt.xlabel('Cycles')\n",
    "# plt.ylabel('RUL')\n",
    "# plt.legend()\n",
    "# plt.savefig('testplot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RUL_Tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
