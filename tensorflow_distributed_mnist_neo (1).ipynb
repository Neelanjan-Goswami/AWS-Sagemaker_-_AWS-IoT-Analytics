{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow BYOM: Train with Custom Training Script, Compile with Neo, and Deploy on SageMaker\n",
    "\n",
    "This notebook can be compared to [TensorFlow MNIST distributed training notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_distributed_mnist/tensorflow_distributed_mnist.ipynb) in terms of its functionality. We will do the same classification task, but this time we will compile the trained model using the Neo API backend, to optimize for our choice of hardware. Finally, we setup a real-time hosted endpoint in SageMaker for our compiled model using the Neo Deep Learning Runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Writing data/train.tfrecords\n",
      "Writing data/validation.tfrecords\n",
      "Writing data/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training \n",
    "Here is the full code for the network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import tensorflow as tf\r\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\r\n",
      "\r\n",
      "INPUT_TENSOR_NAME = 'inputs'\r\n",
      "SIGNATURE_NAME = 'predictions'\r\n",
      "\r\n",
      "LEARNING_RATE = 0.001\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(features, labels, mode, params):\r\n",
      "    # Input Layer\r\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1, 28, 28, 1])\r\n",
      "\r\n",
      "    # Convolutional Layer #1\r\n",
      "    conv1 = tf.layers.conv2d(\r\n",
      "        inputs=input_layer,\r\n",
      "        filters=32,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "\r\n",
      "    # Pooling Layer #1\r\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Convolutional Layer #2 and Pooling Layer #2\r\n",
      "    conv2 = tf.layers.conv2d(\r\n",
      "        inputs=pool1,\r\n",
      "        filters=64,\r\n",
      "        kernel_size=[5, 5],\r\n",
      "        padding='same',\r\n",
      "        activation=tf.nn.relu)\r\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\r\n",
      "\r\n",
      "    # Dense Layer\r\n",
      "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\r\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\r\n",
      "    dropout = tf.layers.dropout(\r\n",
      "        inputs=dense, rate=0.4, training=(mode == Modes.TRAIN))\r\n",
      "\r\n",
      "    # Logits Layer\r\n",
      "    logits = tf.layers.dense(inputs=dropout, units=10)\r\n",
      "\r\n",
      "    # Define operations\r\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\r\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\r\n",
      "\r\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\r\n",
      "        global_step = tf.train.get_or_create_global_step()\r\n",
      "        label_indices = tf.cast(labels, tf.int32)\r\n",
      "        loss = tf.losses.softmax_cross_entropy(\r\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=10), logits=logits)\r\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\r\n",
      "\r\n",
      "    if mode == Modes.PREDICT:\r\n",
      "        predictions = {\r\n",
      "            'probabilities': probabilities\r\n",
      "        }\r\n",
      "        export_outputs = {\r\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\r\n",
      "\r\n",
      "    if mode == Modes.TRAIN:\r\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\r\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\r\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    if mode == Modes.EVAL:\r\n",
      "        eval_metric_ops = {\r\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, tf.argmax(input=logits, axis=1))\r\n",
      "        }\r\n",
      "        return tf.estimator.EstimatorSpec(\r\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn(params):\r\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 784])}\r\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\r\n",
      "def read_and_decode(filename_queue):\r\n",
      "    reader = tf.TFRecordReader()\r\n",
      "    _, serialized_example = reader.read(filename_queue)\r\n",
      "\r\n",
      "    features = tf.parse_single_example(\r\n",
      "        serialized_example,\r\n",
      "        features={\r\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\r\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\r\n",
      "        })\r\n",
      "\r\n",
      "    image = tf.decode_raw(features['image_raw'], tf.uint8)\r\n",
      "    image.set_shape([784])\r\n",
      "    image = tf.cast(image, tf.float32) * (1. / 255)\r\n",
      "    label = tf.cast(features['label'], tf.int32)\r\n",
      "\r\n",
      "    return image, label\r\n",
      "\r\n",
      "\r\n",
      "def train_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def eval_input_fn(training_dir, params):\r\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=100)\r\n",
      "\r\n",
      "\r\n",
      "def _input_fn(training_dir, training_filename, batch_size=100):\r\n",
      "    test_file = os.path.join(training_dir, training_filename)\r\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\r\n",
      "\r\n",
      "    image, label = read_and_decode(filename_queue)\r\n",
      "    images, labels = tf.train.batch(\r\n",
      "        [image, label], batch_size=batch_size,\r\n",
      "        capacity=1000 + 3 * batch_size)\r\n",
      "\r\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\r\n",
      "\r\n",
      "def neo_preprocess(payload, content_type):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import io\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined pre-processing function')\r\n",
      "\r\n",
      "    if content_type != 'application/x-image' and content_type != 'application/vnd+python.numpy+binary':\r\n",
      "        raise RuntimeError('Content type must be application/x-image or application/vnd+python.numpy+binary')\r\n",
      "\r\n",
      "    f = io.BytesIO(payload)\r\n",
      "    image = np.load(f)*255\r\n",
      "\r\n",
      "    return image\r\n",
      "\r\n",
      "### NOTE: this function cannot use MXNet\r\n",
      "def neo_postprocess(result):\r\n",
      "    import logging\r\n",
      "    import numpy as np\r\n",
      "    import json\r\n",
      "\r\n",
      "    logging.info('Invoking user-defined post-processing function')\r\n",
      "\r\n",
      "    # Softmax (assumes batch size 1)\r\n",
      "    result = np.squeeze(result)\r\n",
      "    result_exp = np.exp(result - np.max(result))\r\n",
      "    result = result_exp / np.sum(result_exp)\r\n",
      "\r\n",
      "    response_body = json.dumps(result.tolist())\r\n",
      "    content_type = 'application/json'\r\n",
      "\r\n",
      "    return response_body, content_type\r\n"
     ]
    }
   ],
   "source": [
    "!cat 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script here is and adaptation of the [TensorFlow MNIST example](https://github.com/tensorflow/models/tree/master/official/mnist). It provides a ```model_fn(features, labels, mode)```, which is used for training, evaluation and inference. See [TensorFlow MNIST distributed training notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/tensorflow_distributed_mnist/tensorflow_distributed_mnist.ipynb) for more details about the training script.\n",
    "\n",
    "At the end of the training script, there are two additional functions, to be used with Neo Deep Learning Runtime:\n",
    "* `neo_preprocess(payload, content_type)`: Function that takes in the payload and Content-Type of each incoming request and returns a NumPy array\n",
    "* `neo_postprocess(result)`: Function that takes the prediction results produced by Deep Learining Runtime and returns the response body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.TensorFlow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-26 12:20:55 Starting - Starting the training job...\n",
      "2020-09-26 12:20:57 Starting - Launching requested ML instances......\n",
      "2020-09-26 12:22:24 Starting - Preparing the instances for training......\n",
      "2020-09-26 12:23:18 Downloading - Downloading input data\n",
      "2020-09-26 12:23:18 Training - Downloading the training image..\u001b[35m2020-09-26 12:23:30,969 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:30,969 INFO - root - starting train task\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:30,983 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[35mDownloading s3://tensorflowtrial/sagemaker-tensorflow-2020-09-26-12-20-55-696/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,566 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'worker'}}\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,567 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,567 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9ba7c45910>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[35mdevice_filters: \"/job:worker/task:0\"\u001b[0m\n",
      "\u001b[35mallow_soft_placement: true\u001b[0m\n",
      "\u001b[35mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m, '_global_id_in_cluster': 1, '_is_chief': False, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints', '_master': u'grpc://algo-2:2222'}\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,570 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:33,588 INFO - tensorflow - Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:38.655837: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:38.656583: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:38,789 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:38,790 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:38,814 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:39,142 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:39,143 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:39,267 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:38,457 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:38,457 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:38,470 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://tensorflowtrial/sagemaker-tensorflow-2020-09-26-12-20-55-696/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,088 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,090 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f179da3d910>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints', '_master': u'grpc://algo-1:2222'}\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,091 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.239947: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.240802: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,373 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,375 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:187: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,399 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:23:42,021 INFO - tensorflow - Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, conv2d/kernel, conv2d/bias, conv2d_1/kernel, conv2d_1/bias, dense/kernel, dense/bias, dense_1/kernel, dense_1/bias, beta1_power, beta2_power, conv2d/kernel/Adam, conv2d/kernel/Adam_1, conv2d/bias/Adam, conv2d/bias/Adam_1, conv2d_1/kernel/Adam, conv2d_1/kernel/Adam_1, conv2d_1/bias/Adam, conv2d_1/bias/Adam_1, dense/kernel/Adam, dense/kernel/Adam_1, dense/bias/Adam, dense/bias/Adam_1, dense_1/kernel/Adam, dense_1/kernel/Adam_1, dense_1/bias/Adam, dense_1/bias/Adam_1, ready: None\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,715 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41,716 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.729996: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.730031: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.751056: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.751101: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.773346: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.773384: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.798633: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:41.798666: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42,193 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42.201932: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42.201967: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42,610 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42,615 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42,645 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42.725225: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:42.725273: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:43,515 INFO - tensorflow - Saving checkpoints for 0 into s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/model.ckpt.\u001b[0m\n",
      "\n",
      "2020-09-26 12:23:38 Training - Training image download completed. Training in progress.\u001b[34m2020-09-26 12:23:45.874731: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:45.874773: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:23:46,649 INFO - tensorflow - loss = 2.3124442, step = 0\u001b[0m\n",
      "\u001b[35m2020-09-26 12:24:12,121 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:24:12,130 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:24:12,166 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2020-09-26 12:24:12,730 INFO - tensorflow - loss = 0.17376642, step = 93\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:13,867 INFO - tensorflow - global_step/sec: 3.74732\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:15,178 INFO - tensorflow - loss = 0.099401675, step = 110 (28.530 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:27,608 INFO - tensorflow - global_step/sec: 7.42263\u001b[0m\n",
      "\u001b[35m2020-09-26 12:24:37,298 INFO - tensorflow - loss = 0.017915882, step = 275 (24.569 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:41,677 INFO - tensorflow - global_step/sec: 7.32113\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:44,860 INFO - tensorflow - loss = 0.047099445, step = 330 (29.682 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:24:55,479 INFO - tensorflow - global_step/sec: 7.3903\u001b[0m\n",
      "\u001b[35m2020-09-26 12:25:02,507 INFO - tensorflow - loss = 0.013219688, step = 459 (25.209 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:09,536 INFO - tensorflow - global_step/sec: 7.32752\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:14,605 INFO - tensorflow - loss = 0.048658647, step = 548 (29.744 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:23,286 INFO - tensorflow - global_step/sec: 7.41787\u001b[0m\n",
      "\u001b[35m2020-09-26 12:25:27,525 INFO - tensorflow - loss = 0.029819574, step = 643 (25.018 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:37,530 INFO - tensorflow - global_step/sec: 7.23141\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:44,321 INFO - tensorflow - loss = 0.045595873, step = 764 (29.716 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:25:51,876 INFO - tensorflow - global_step/sec: 7.10994\u001b[0m\n",
      "\u001b[35m2020-09-26 12:25:53,523 INFO - tensorflow - loss = 0.049105592, step = 830 (25.998 sec)\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:05,907 INFO - tensorflow - global_step/sec: 7.26977\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:14,160 INFO - tensorflow - loss = 0.003924444, step = 977 (29.839 sec)\u001b[0m\n",
      "\u001b[35m2020-09-26 12:26:17,227 INFO - tensorflow - Loss for final step: 0.036727138.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:17,176 INFO - tensorflow - Saving checkpoints for 1001 into s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:19.888133: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:19.888175: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,288 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,464 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,482 INFO - tensorflow - Starting evaluation at 2020-09-26-12:26:20\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,552 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,613 INFO - tensorflow - Restoring parameters from s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,947 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:20,956 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:21,575 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:22,005 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:22,453 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:22,905 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:23,352 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:23,823 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:24,268 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:24,692 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25,142 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25,577 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25,604 INFO - tensorflow - Finished evaluation at 2020-09-26-12:26:25\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25,604 INFO - tensorflow - Saving dict for global step 1002: accuracy = 0.9881, global_step = 1002, loss = 0.03761258\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.617221: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.617256: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.636752: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.636789: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.654377: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25.654429: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:25,912 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1002: s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.004135: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.004191: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.028874: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.028916: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.051057: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.051097: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.072230: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.072265: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.094537: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:26.094583: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:27.751989: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 500\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:27.752038: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:27.752056: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 0 ms before attempting again.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:27.775881: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:27.775914: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,091 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,150 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,151 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,151 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,151 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,151 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,151 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,224 INFO - tensorflow - Restoring parameters from s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,533 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1018: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,534 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28,534 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.547749: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.547806: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.568881: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.568910: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.586679: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:28.586714: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:29.699500: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:29.699546: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:29,762 INFO - tensorflow - SavedModel written to: s3://tensorflowtrial/artifacts/sagemaker-tensorflow-2020-09-26-12-20-55-696/checkpoints/export/Servo/temp-1601123185/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:29.769800: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:29.769834: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30.201860: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30.201903: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30.222764: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30.222809: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30,368 INFO - tensorflow - Loss for final step: 0.063501626.\u001b[0m\n",
      "\u001b[34m2020-09-26 12:26:30,653 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1601123185\u001b[0m\n",
      "\u001b[35m2020-09-26 12:27:45,193 INFO - tf_container - master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\n",
      "2020-09-26 12:28:47 Uploading - Uploading generated training model\n",
      "2020-09-26 12:28:47 Completed - Training job completed\n",
      "Training seconds: 674\n",
      "Billable seconds: 674\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.11.0',\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "mnist_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **```fit```** method will create a training job in two **ml.c4.xlarge** instances. The logs above will show the instances doing training, evaluation, and incrementing the number of **training steps**. \n",
    "\n",
    "In the end of the training, the training job will generate a saved model for TF serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to prepare for predictions (the old way)\n",
    "\n",
    "The deploy() method creates an endpoint which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sagemaker-ap-southeast-1-018166606076/tensorflow-training-2020-09-26-11-19-40-794/output/model.tar.gz.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b7b00d3481ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mnist_predictor = mnist_estimator.deploy(initial_instance_count=1,\n\u001b[0;32m----> 2\u001b[0;31m                                          instance_type='ml.m4.xlarge')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, use_compiled_model, update_endpoint, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         )\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/tensorflow/serving.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, accelerator_type, endpoint_name, update_endpoint, tags, kms_key, wait, data_capture_config)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sagemaker_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         production_variant = sagemaker.production_variant(\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mvpc_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvpc_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0menable_network_isolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_network_isolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcreate_model_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sagemaker-ap-southeast-1-018166606076/tensorflow-training-2020-09-26-11-19-40-794/output/model.tar.gz."
     ]
    }
   ],
   "source": [
    "mnist_predictor = mnist_estimator.deploy(initial_instance_count=1,\n",
    "                                         instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "for i in range(10):\n",
    "    data = mnist.test.images[i].tolist()\n",
    "    tensor_proto = tf.make_tensor_proto(values=np.asarray(data), shape=[1, len(data)], dtype=tf.float32)\n",
    "    predict_response = mnist_predictor.predict(tensor_proto)\n",
    "    \n",
    "    print(\"========================================\")\n",
    "    label = np.argmax(mnist.test.labels[i])\n",
    "    print(\"label is {}\".format(label))\n",
    "    prediction = np.argmax(predict_response['outputs']['probabilities']['float_val'])\n",
    "    print(\"prediction is {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(mnist_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model using Neo\n",
    "\n",
    "Now the model is ready to be compiled by Neo to be optimized for our hardware of choice. We are using the  ``TensorFlowEstimator.compile_model`` method to do this. For this example, our target hardware is ``'ml_c5'``. You can changed these to other supported target hardware if you prefer.\n",
    "\n",
    "## Compiling the model\n",
    "The ``input_shape`` is the definition for the model's input tensor and ``output_path`` is where the compiled model will be stored in S3. **Important. If the following command result in a permission error, scroll up and locate the value of execution role returned by `get_execution_role()`. The role must have access to the S3 bucket specified in ``output_path``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "2.1.0 is the latest version of tensorflow that supports Python 2. Newer versions of tensorflow will only be available for Python 3.Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://tensorflowtrial\n",
      "?.....*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Compilation job compilation-sagemaker-tensorflow-2020-09-26-13-14-16-792: Failed. Reason: ClientError: InputConfiguration: Check 1. Input names and shapes matches with trained model. 2. If you are compiling MXNet model, make sure .params file only contains model weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1bd94c1ebea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Batch size 1, 3 channels, 224x224 Images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m's3://tensorflowtrial/artifacts/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               framework='tensorflow', framework_version='1.11.0')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mcompile_model\u001b[0;34m(self, target_instance_family, input_shape, output_path, framework, framework_version, compile_max_run, tags, target_platform_os, target_platform_arch, target_platform_accelerator, compiler_options, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mtarget_platform_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_platform_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mtarget_platform_accelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_platform_accelerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0mcompiler_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompiler_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         )\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_instance_family\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, target_instance_family, input_shape, output_path, role, tags, job_name, compile_max_run, framework, framework_version, target_platform_os, target_platform_arch, target_platform_accelerator, compiler_options)\u001b[0m\n\u001b[1;32m    434\u001b[0m         )\n\u001b[1;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mjob_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_compilation_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ModelArtifacts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S3ModelArtifacts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_instance_family\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_compilation_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   2575\u001b[0m         \"\"\"\n\u001b[1;32m   2576\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_compilation_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CompilationJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                 ),\n\u001b[1;32m   2670\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m             )\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Compilation job compilation-sagemaker-tensorflow-2020-09-26-13-14-16-792: Failed. Reason: ClientError: InputConfiguration: Check 1. Input names and shapes matches with trained model. 2. If you are compiling MXNet model, make sure .params file only contains model weights."
     ]
    }
   ],
   "source": [
    "#output_path = '/'.join(mnist_estimator.output_path.split('/')[:-1])\n",
    "\n",
    "print(output_path)\n",
    "\n",
    "\n",
    "optimized_estimator = mnist_estimator.compile_model(target_instance_family='rasp3b', \n",
    "                              input_shape= {'data':[1, 784]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "                              framework='tensorflow', framework_version='1.11.0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_predictor = optimized_estimator.deploy(initial_instance_count = 1,\n",
    "                                                 instance_type = 'ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_bytes_serializer(data):\n",
    "    f = io.BytesIO()\n",
    "    np.save(f, data)\n",
    "    f.seek(0)\n",
    "    return f.read()\n",
    "\n",
    "optimized_predictor.content_type = 'application/vnd+python.numpy+binary'\n",
    "optimized_predictor.serializer = numpy_bytes_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from IPython import display\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "for i in range(10):\n",
    "    data = mnist.test.images[i]\n",
    "    # Display image\n",
    "    im = PIL.Image.fromarray(data.reshape((28,28))*255).convert('L')\n",
    "    display.display(im)\n",
    "    # Invoke endpoint with image\n",
    "    predict_response = optimized_predictor.predict(data)\n",
    "    \n",
    "    print(\"========================================\")\n",
    "    label = np.argmax(mnist.test.labels[i])\n",
    "    print(\"label is {}\".format(label))\n",
    "    prediction = predict_response\n",
    "    print(\"prediction is {}\".format(np.argmax(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(optimized_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
